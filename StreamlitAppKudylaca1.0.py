import streamlit as st
import os
from typing import Dict, List, Tuple, Any
import tempfile

class MorphemicConlluSplitter:
    """–°–∏—Å—Ç–µ–º–∞ –º–æ—Ä—Ñ–µ–º–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –Ω–∞ —Ç—Ä–∏ CONLLU —Ñ–∞–π–ª–∞"""
    
    def __init__(self):
        self.affix_features = {
            # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã
            'ha': {'upos': 'PREF', 'feats': 'Tense=Past'},
            'ake': {'upos': 'PREF', 'feats': 'Tense=Present'},
            'ka': {'upos': 'PREF', 'feats': 'Tense=Future'},
            'to': {'upos': 'PREF', 'feats': 'Tense=Future'},
            'te': {'upos': 'PREF', 'feats': 'Tense=Present'},
            'ta': {'upos': 'PREF', 'feats': 'Tense=Past'},
            
            # –°—É—Ñ—Ñ–∏–∫—Å—ã
            'ye': {'upos': 'SUFF', 'feats': 'VerbForm=Fin'},
            'yemu': {'upos': 'SUFF', 'feats': 'VerbForm=Conv'},
            'yepi': {'upos': 'SUFF', 'feats': 'VerbForm=Part'},
            'mu': {'upos': 'SUFF', 'feats': 'Derivation=Quality'},
            'pi': {'upos': 'SUFF', 'feats': 'Derivation=Relation'}
        }
        
        # –°–ª–æ–≤–∞—Ä—å –∫–æ—Ä–Ω–µ–π-—Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã—Ö
        self.noun_roots = {
            'laca': '—á–µ–ª–æ–≤–µ–∫', 'tala': '—Å–º–µ—Ä—Ç—å', 'laa': '–≤–µ—Ç–µ—Ä', 
            'haka': '–æ–≥–æ–Ω—å', 'naro': '–≤–æ–¥–∞', 'ku': '—è', 'gy': '—Ç—ã',
            'ka': '—á—Ç–æ', 'la': '–≤–µ—Ç–µ—Ä', 'ranil': '—Å–æ–ª–Ω—Ü–µ', 'sari': '–ø–µ–Ω–∏–µ'
        }
    
    def analyze_word(self, word: str) -> Dict:
        """–ü—Ä–æ–≤–æ–¥–∏—Ç –º–æ—Ä—Ñ–µ–º–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–ª–æ–≤–∞"""
        morphemes = self._split_into_morphemes(word)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º UPOS –∫–æ—Ä–Ω—è
        root_upos = 'NOUN' if any(root in word for root in self.noun_roots) else 'VERB'
        
        return {
            'original_word': word,
            'morphemes': morphemes,
            'root_upos': root_upos
        }
    
    def _split_into_morphemes(self, word: str) -> List[Tuple[str, str]]:
        """–†–∞–∑–±–∏–≤–∞–µ—Ç —Å–ª–æ–≤–æ –Ω–∞ –º–æ—Ä—Ñ–µ–º—ã —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –∏—Ö —Ç–∏–ø–æ–≤"""
        morphemes = []
        remaining_word = word
        
        # –ò—â–µ–º –ø—Ä–µ—Ñ–∏–∫—Å—ã
        prefixes_found = True
        while prefixes_found and remaining_word:
            prefixes_found = False
            for prefix in ['ake', 'ha', 'ka', 'to', 'te', 'ta']:
                if remaining_word.startswith(prefix):
                    morphemes.append((prefix, 'time_prefix'))
                    remaining_word = remaining_word[len(prefix):]
                    prefixes_found = True
                    break
        
        # –ò—â–µ–º –∫–æ—Ä–Ω–∏ (—Å–∞–º—ã–π –¥–ª–∏–Ω–Ω—ã–π —Å–æ–≤–ø–∞–¥–∞—é—â–∏–π –∫–æ—Ä–µ–Ω—å —Å–Ω–∞—á–∞–ª–∞)
        root_found = False
        for root in sorted(self.noun_roots.keys(), key=len, reverse=True):
            if remaining_word.startswith(root):
                morphemes.append((root, 'root'))
                remaining_word = remaining_word[len(root):]
                root_found = True
                break
        
        # –ï—Å–ª–∏ –∫–æ—Ä–µ–Ω—å –Ω–µ –Ω–∞–π–¥–µ–Ω —Å—Ä–µ–¥–∏ —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã—Ö, –±–µ—Ä–µ–º –ø–µ—Ä–≤—É—é —á–∞—Å—Ç—å –∫–∞–∫ –∫–æ—Ä–µ–Ω—å
        if not root_found and remaining_word:
            # –≠–≤—Ä–∏—Å—Ç–∏–∫–∞: –µ—Å–ª–∏ —Å–ª–æ–≤–æ –∫–æ—Ä–æ—Ç–∫–æ–µ, —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –º–µ—Å—Ç–æ–∏–º–µ–Ω–∏–µ
            if len(remaining_word) <= 2:
                morphemes.append((remaining_word, 'root'))
                remaining_word = ""
            else:
                # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∫–æ—Ä–µ–Ω—å –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º
                for i in range(min(4, len(remaining_word)), 0, -1):
                    potential_root = remaining_word[:i]
                    if any(noun_root.startswith(potential_root) for noun_root in self.noun_roots):
                        morphemes.append((potential_root, 'root'))
                        remaining_word = remaining_word[i:]
                        break
                else:
                    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é —á–∞—Å—Ç—å –∫–∞–∫ –∫–æ—Ä–µ–Ω—å
                    root_length = min(3, len(remaining_word))
                    morphemes.append((remaining_word[:root_length], 'root'))
                    remaining_word = remaining_word[root_length:]
        
        # –ò—â–µ–º —Å—É—Ñ—Ñ–∏–∫—Å—ã
        suffixes_found = True
        while suffixes_found and remaining_word:
            suffixes_found = False
            for suffix in ['yepi', 'yemu', 'ye', 'mu', 'pi']:
                if remaining_word.endswith(suffix):
                    morphemes.append((suffix, 'suffix'))
                    remaining_word = remaining_word[:-len(suffix)]
                    suffixes_found = True
                    break
        
        # –û—Å—Ç–∞—Ç–æ–∫ –ø–æ–º–µ—á–∞–µ–º –∫–∞–∫ unknown
        if remaining_word:
            morphemes.append((remaining_word, 'unknown'))
        
        return morphemes
    
    def generate_separate_conllu_files(self, words: List[str], base_output_path: str) -> Dict[str, str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç—Ä–∏ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö CONLLU —Ñ–∞–π–ª–∞"""
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–æ–≤
        affixes_content = [
            "# affixes.conllu - —Ç–æ–ª—å–∫–æ –∞—Ñ—Ñ–∏–∫—Å—ã", 
            "# language: kudylaca",
            "# sent_id | form | lemma | upos | xpos | feats | head | deprel | deps | misc",
            ""
        ]
        
        roots_content = [
            "# roots.conllu - —Ç–æ–ª—å–∫–æ –∫–æ—Ä–Ω–∏-—Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ", 
            "# language: kudylaca",
            "# sent_id | form | lemma | upos | xpos | feats | head | deprel | deps | misc",
            ""
        ]
        
        other_content = [
            "# other.conllu - –≤—Å—ë –æ—Å—Ç–∞–ª—å–Ω–æ–µ", 
            "# language: kudylaca",
            "# sent_id | form | lemma | upos | xpos | feats | head | deprel | deps | misc",
            ""
        ]
        
        sentence_id = 1
        
        for word in words:
            analysis = self.analyze_word(word)
            morphemes = analysis['morphemes']
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∑–∞–ø–∏—Å–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ –º–æ—Ä—Ñ–µ–º
            affix_records = []
            root_records = []
            other_records = []
            
            morpheme_position = 1
            
            for morpheme_form, morpheme_type in morphemes:
                conllu_line = self._create_conllu_line(
                    morpheme_form, morpheme_type, analysis, morpheme_position
                )
                
                # –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ —Ñ–∞–π–ª–∞–º
                if morpheme_type in ['time_prefix', 'suffix']:
                    affix_records.append(conllu_line)
                elif morpheme_type == 'root' and analysis['root_upos'] == 'NOUN':
                    root_records.append(conllu_line)
                else:
                    other_records.append(conllu_line)
                
                morpheme_position += 1
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã, –µ—Å–ª–∏ –µ—Å—Ç—å –∑–∞–ø–∏—Å–∏
            if affix_records:
                affixes_content.append(f"# sent_id = {sentence_id}")
                affixes_content.append(f"# text = {word}")
                affixes_content.extend(affix_records)
                affixes_content.append("")
            
            if root_records:
                roots_content.append(f"# sent_id = {sentence_id}")
                roots_content.append(f"# text = {word}")
                roots_content.extend(root_records)
                roots_content.append("")
            
            if other_records:
                other_content.append(f"# sent_id = {sentence_id}")
                other_content.append(f"# text = {word}")
                other_content.extend(other_records)
                other_content.append("")
            
            sentence_id += 1
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª—ã
        results = {}
        
        affixes_path = f"{base_output_path}_affixes.conllu"
        with open(affixes_path, 'w', encoding='utf-8', newline='\n') as f:
            f.write("\n".join(affixes_content))
        results['affixes'] = affixes_path
        
        roots_path = f"{base_output_path}_roots.conllu"
        with open(roots_path, 'w', encoding='utf-8', newline='\n') as f:
            f.write("\n".join(roots_content))
        results['roots'] = roots_path
        
        other_path = f"{base_output_path}_other.conllu"
        with open(other_path, 'w', encoding='utf-8', newline='\n') as f:
            f.write("\n".join(other_content))
        results['other'] = other_path
        
        return results
    
    def generate_conllu_content(self, words: List[str]) -> Dict[str, str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ CONLLU —Ñ–∞–π–ª–æ–≤ –±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–∞ –¥–∏—Å–∫"""
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–æ–≤
        affixes_content = [
            "# affixes.conllu - —Ç–æ–ª—å–∫–æ –∞—Ñ—Ñ–∏–∫—Å—ã", 
            "# language: kudylaca",
            "# sent_id | form | lemma | upos | xpos | feats | head | deprel | deps | misc",
            ""
        ]
        
        roots_content = [
            "# roots.conllu - —Ç–æ–ª—å–∫–æ –∫–æ—Ä–Ω–∏-—Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ", 
            "# language: kudylaca",
            "# sent_id | form | lemma | upos | xpos | feats | head | deprel | deps | misc",
            ""
        ]
        
        other_content = [
            "# other.conllu - –≤—Å—ë –æ—Å—Ç–∞–ª—å–Ω–æ–µ", 
            "# language: kudylaca",
            "# sent_id | form | lemma | upos | xpos | feats | head | deprel | deps | misc",
            ""
        ]
        
        sentence_id = 1
        
        for word in words:
            analysis = self.analyze_word(word)
            morphemes = analysis['morphemes']
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∑–∞–ø–∏—Å–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ –º–æ—Ä—Ñ–µ–º
            affix_records = []
            root_records = []
            other_records = []
            
            morpheme_position = 1
            
            for morpheme_form, morpheme_type in morphemes:
                conllu_line = self._create_conllu_line(
                    morpheme_form, morpheme_type, analysis, morpheme_position
                )
                
                # –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ —Ñ–∞–π–ª–∞–º
                if morpheme_type in ['time_prefix', 'suffix']:
                    affix_records.append(conllu_line)
                elif morpheme_type == 'root' and analysis['root_upos'] == 'NOUN':
                    root_records.append(conllu_line)
                else:
                    other_records.append(conllu_line)
                
                morpheme_position += 1
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã, –µ—Å–ª–∏ –µ—Å—Ç—å –∑–∞–ø–∏—Å–∏
            if affix_records:
                affixes_content.append(f"# sent_id = {sentence_id}")
                affixes_content.append(f"# text = {word}")
                affixes_content.extend(affix_records)
                affixes_content.append("")
            
            if root_records:
                roots_content.append(f"# sent_id = {sentence_id}")
                roots_content.append(f"# text = {word}")
                roots_content.extend(root_records)
                roots_content.append("")
            
            if other_records:
                other_content.append(f"# sent_id = {sentence_id}")
                other_content.append(f"# text = {word}")
                other_content.extend(other_records)
                other_content.append("")
            
            sentence_id += 1
        
        return {
            'affixes': "\n".join(affixes_content),
            'roots': "\n".join(roots_content),
            'other': "\n".join(other_content)
        }
    
    def _create_conllu_line(self, form: str, morpheme_type: str, analysis: Dict, position: int) -> str:
        """–°–æ–∑–¥–∞–µ—Ç —Å—Ç—Ä–æ–∫—É CONLLU –¥–ª—è –º–æ—Ä—Ñ–µ–º—ã"""
        
        # –ë–∞–∑–æ–≤—ã–µ –ø–æ–ª—è
        fields = {
            'id': str(position),
            'form': form,
            'lemma': form,
            'upos': 'X',
            'xpos': '_',
            'feats': '_',
            'head': '0',
            'deprel': 'root',
            'deps': '_',
            'misc': '_'
        }
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –º–æ—Ä—Ñ–µ–º—ã
        if morpheme_type in ['time_prefix', 'suffix']:
            affix_info = self.affix_features.get(form, {})
            fields['upos'] = affix_info.get('upos', 'PREF' if morpheme_type == 'time_prefix' else 'SUFF')
            fields['feats'] = affix_info.get('feats', '_')
            fields['misc'] = f"Type={morpheme_type}"
            
        elif morpheme_type == 'root':
            if analysis['root_upos'] == 'NOUN':
                fields['upos'] = 'NOUN'
                meaning = self.noun_roots.get(form, 'unknown')
                fields['feats'] = f"Meaning={meaning}"
                fields['misc'] = "Type=root_noun"
            else:
                fields['upos'] = analysis['root_upos']
                fields['misc'] = f"Type=root_{analysis['root_upos'].lower()}"
                
        else:  # unknown
            fields['misc'] = f"NotMorpheme|Type={morpheme_type}"
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫—É CONLLU
        return f"{fields['id']}\t{fields['form']}\t{fields['lemma']}\t{fields['upos']}\t{fields['xpos']}\t{fields['feats']}\t{fields['head']}\t{fields['deprel']}\t{fields['deps']}\t{fields['misc']}"

    def demonstrate_analysis(self, words: List[str]):
        """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ —Å–ª–æ–≤"""
        st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–æ—Ä—Ñ–µ–º–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
        
        for word in words:
            st.write(f"**–°–ª–æ–≤–æ:** `{word}`")
            analysis = self.analyze_word(word)
            morphemes = analysis['morphemes']
            
            # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –º–æ—Ä—Ñ–µ–º–Ω—ã–π —Ä–∞–∑–±–æ—Ä
            morphemes_text = " + ".join([f"{form} ({mtype})" for form, mtype in morphemes])
            st.write(f"**–ú–æ—Ä—Ñ–µ–º–Ω—ã–π —Ä–∞–∑–±–æ—Ä:** {morphemes_text}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ñ–∞–π–ª–∞–º
            affixes = [f for f, t in morphemes if t in ['time_prefix', 'suffix']]
            roots = [f for f, t in morphemes if t == 'root' and analysis['root_upos'] == 'NOUN']
            other = [f for f, t in morphemes if not (t in ['time_prefix', 'suffix'] or 
                                                     (t == 'root' and analysis['root_upos'] == 'NOUN'))]
            
            st.write("**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ñ–∞–π–ª–∞–º CONLLU:**")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                if affixes:
                    st.info(f"üìÅ **affixes.conllu:** {', '.join(affixes)}")
                else:
                    st.info("üìÅ **affixes.conllu:** -")
            
            with col2:
                if roots:
                    st.success(f"üìÅ **roots.conllu:** {', '.join(roots)}")
                else:
                    st.success("üìÅ **roots.conllu:** -")
            
            with col3:
                if other:
                    st.warning(f"üìÅ **other.conllu:** {', '.join(other)}")
                else:
                    st.warning("üìÅ **other.conllu:** -")
            
            st.divider()

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è Streamlit –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    st.set_page_config(
        page_title="Morphemic Analyzer",
        page_icon="üìö",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
    st.title("üìö –°–∏—Å—Ç–µ–º–∞ –º–æ—Ä—Ñ–µ–º–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ KUDYLACA")
    st.markdown("### —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –Ω–∞ 3 CONLLU —Ñ–∞–π–ª–∞")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
    if 'splitter' not in st.session_state:
        st.session_state.splitter = MorphemicConlluSplitter()
    
    splitter = st.session_state.splitter
    
    # –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å —Å –Ω–∞–≤–∏–≥–∞—Ü–∏–µ–π
    st.sidebar.title("–ù–∞–≤–∏–≥–∞—Ü–∏—è")
    option = st.sidebar.radio(
        "–í—ã–±–µ—Ä–∏—Ç–µ –æ–ø—Ü–∏—é:",
        ["üè† –ì–ª–∞–≤–Ω–∞—è", "üîç –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞", "üìù –ê–Ω–∞–ª–∏–∑ —Å–≤–æ–∏—Ö —Å–ª–æ–≤", "üíæ –°–æ–∑–¥–∞–Ω–∏–µ CONLLU —Ñ–∞–π–ª–æ–≤"]
    )
    
    # –ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞
    if option == "üè† –ì–ª–∞–≤–Ω–∞—è":
        st.header("–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ —Å–∏—Å—Ç–µ–º—É –º–æ—Ä—Ñ–µ–º–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞!")
        
        st.markdown("""
        –≠—Ç–∞ —Å–∏—Å—Ç–µ–º–∞ –≤—ã–ø–æ–ª–Ω—è–µ—Ç –º–æ—Ä—Ñ–µ–º–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–ª–æ–≤ —è–∑—ã–∫–∞ KUDYLACA –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç—Ä–∏ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö CONLLU —Ñ–∞–π–ª–∞:
        
        - üìÅ **affixes.conllu** - –ø—Ä–µ—Ñ–∏–∫—Å—ã –∏ —Å—É—Ñ—Ñ–∏–∫—Å—ã
        - üìÅ **roots.conllu** - –∫–æ—Ä–Ω–∏-—Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ  
        - üìÅ **other.conllu** - –≤—Å—ë –æ—Å—Ç–∞–ª—å–Ω–æ–µ
        
        ### –ü—Ä–∏–º–µ—Ä—ã —Å–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:
        - `halacayemu` - —á–µ–ª–æ–≤–µ–∫ (–ø—Ä–æ—à–µ–¥—à–µ–µ –≤—Ä–µ–º—è, –¥–µ–µ–ø—Ä–∏—á–∞—Å—Ç–∏–µ)
        - `takulaye` - —è (–±—É–¥—É—â–µ–µ –≤—Ä–µ–º—è, –∏–∑—ä—è–≤–∏—Ç–µ–ª—å–Ω–æ–µ –Ω–∞–∫–ª–æ–Ω–µ–Ω–∏–µ)
        - `sarimu` - –ø–µ–Ω–∏–µ (–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ)
        - `aketolaye` - (–Ω–∞—Å—Ç–æ—è—â–µ–µ/–±—É–¥—É—â–µ–µ –≤—Ä–µ–º—è)
        """)
        
        # –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç
        if st.button("üöÄ –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –Ω–∞ –ø—Ä–∏–º–µ—Ä–∞—Ö"):
            test_words = ["halacayemu", "takulaye", "sarimu", "aketolaye", "gy", "tolacaye"]
            splitter.demonstrate_analysis(test_words)
    
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞
    elif option == "üîç –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞":
        st.header("–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –º–æ—Ä—Ñ–µ–º–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
        
        st.info("""
        –ù–∞ —ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ –≤—ã –º–æ–∂–µ—Ç–µ —É–≤–∏–¥–µ—Ç—å –∞–Ω–∞–ª–∏–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤—ã—Ö —Å–ª–æ–≤.
        –°–∏—Å—Ç–µ–º–∞ –ø–æ–∫–∞–∂–µ—Ç –º–æ—Ä—Ñ–µ–º–Ω—ã–π —Ä–∞–∑–±–æ—Ä –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞ –∏ –µ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ CONLLU —Ñ–∞–π–ª–∞–º.
        """)
        
        test_words = ["halacayemu", "takulaye", "sarimu", "aketolaye", "gy", "tolacaye"]
        
        if st.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—é"):
            splitter.demonstrate_analysis(test_words)
    
    # –ê–Ω–∞–ª–∏–∑ —Å–≤–æ–∏—Ö —Å–ª–æ–≤
    elif option == "üìù –ê–Ω–∞–ª–∏–∑ —Å–≤–æ–∏—Ö —Å–ª–æ–≤":
        st.header("–ê–Ω–∞–ª–∏–∑ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö —Å–ª–æ–≤")
        
        st.info("""
        –í–≤–µ–¥–∏—Ç–µ —Å–ª–æ–≤–∞ –¥–ª—è –º–æ—Ä—Ñ–µ–º–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞. –ö–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–π —Å—Ç—Ä–æ–∫–µ.
        –ü—Ä–∏–º–µ—Ä—ã: `halacayemu`, `takulaye`, `sarimu`, `aketolaye`
        """)
        
        # –ü–æ–ª–µ –¥–ª—è –≤–≤–æ–¥–∞ —Å–ª–æ–≤
        words_input = st.text_area(
            "–í–≤–µ–¥–∏—Ç–µ —Å–ª–æ–≤–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:",
            height=150,
            placeholder="halacayemu\ntakulaye\nsarimu\naketolaye"
        )
        
        if st.button("–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–ª–æ–≤–∞"):
            if words_input.strip():
                words = [word.strip() for word in words_input.split('\n') if word.strip()]
                splitter.demonstrate_analysis(words)
            else:
                st.error("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ —Å–ª–æ–≤–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ CONLLU —Ñ–∞–π–ª–æ–≤
    elif option == "üíæ –°–æ–∑–¥–∞–Ω–∏–µ CONLLU —Ñ–∞–π–ª–æ–≤":
        st.header("–°–æ–∑–¥–∞–Ω–∏–µ CONLLU —Ñ–∞–π–ª–æ–≤")
        
        st.info("""
        –ù–∞ —ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ –≤—ã –º–æ–∂–µ—Ç–µ –≤–≤–µ—Å—Ç–∏ —Å–ª–æ–≤–∞ –∏ –ø–æ–ª—É—á–∏—Ç—å —Ç—Ä–∏ CONLLU —Ñ–∞–π–ª–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞.
        –§–∞–π–ª—ã –º–æ–∂–Ω–æ –±—É–¥–µ—Ç –ø—Ä–æ—Å–º–æ—Ç—Ä–µ—Ç—å –æ–Ω–ª–∞–π–Ω –∏–ª–∏ —Å–∫–∞—á–∞—Ç—å.
        """)
        
        # –ü–æ–ª–µ –¥–ª—è –≤–≤–æ–¥–∞ —Å–ª–æ–≤
        words_input = st.text_area(
            "–í–≤–µ–¥–∏—Ç–µ —Å–ª–æ–≤–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è CONLLU —Ñ–∞–π–ª–æ–≤:",
            height=150,
            placeholder="halacayemu\ntakulaye\nsarimu\naketolaye",
            key="conllu_words"
        )
        
        base_filename = st.text_input("–ë–∞–∑–æ–≤–æ–µ –∏–º—è –¥–ª—è —Ñ–∞–π–ª–æ–≤ (–±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è):", value="morphemic_analysis")
        
        if st.button("–°–æ–∑–¥–∞—Ç—å CONLLU —Ñ–∞–π–ª—ã"):
            if words_input.strip():
                words = [word.strip() for word in words_input.split('\n') if word.strip()]
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–æ–≤
                conllu_content = splitter.generate_conllu_content(words)
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–æ–≤
                st.success("‚úÖ CONLLU —Ñ–∞–π–ª—ã —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω—ã!")
                
                # –í–∫–ª–∞–¥–∫–∏ –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
                tab1, tab2, tab3 = st.tabs(["üìÅ Affixes", "üìÅ Roots", "üìÅ Other"])
                
                with tab1:
                    st.subheader("affixes.conllu")
                    st.code(conllu_content['affixes'], language="text")
                    
                    # –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
                    st.download_button(
                        label="üì• –°–∫–∞—á–∞—Ç—å affixes.conllu",
                        data=conllu_content['affixes'],
                        file_name=f"{base_filename}_affixes.conllu",
                        mime="text/plain"
                    )
                
                with tab2:
                    st.subheader("roots.conllu")
                    st.code(conllu_content['roots'], language="text")
                    
                    # –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
                    st.download_button(
                        label="üì• –°–∫–∞—á–∞—Ç—å roots.conllu",
                        data=conllu_content['roots'],
                        file_name=f"{base_filename}_roots.conllu",
                        mime="text/plain"
                    )
                
                with tab3:
                    st.subheader("other.conllu")
                    st.code(conllu_content['other'], language="text")
                    
                    # –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
                    st.download_button(
                        label="üì• –°–∫–∞—á–∞—Ç—å other.conllu",
                        data=conllu_content['other'],
                        file_name=f"{base_filename}_other.conllu",
                        mime="text/plain"
                    )
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∞–Ω–∞–ª–∏–∑ —Å–ª–æ–≤
                st.subheader("üìä –ê–Ω–∞–ª–∏–∑ —Å–ª–æ–≤")
                splitter.demonstrate_analysis(words)
                
            else:
                st.error("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ —Å–ª–æ–≤–æ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤.")
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —è–∑—ã–∫–µ –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏
    st.sidebar.markdown("---")
    st.sidebar.subheader("–û —è–∑—ã–∫–µ KUDYLACA")
    st.sidebar.markdown("""
    **–ö–æ—Ä–Ω–∏-—Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ:**
    - laca - —á–µ–ª–æ–≤–µ–∫
    - tala - —Å–º–µ—Ä—Ç—å  
    - laa - –≤–µ—Ç–µ—Ä
    - haka - –æ–≥–æ–Ω—å
    - naro - –≤–æ–¥–∞
    
    **–ê—Ñ—Ñ–∏–∫—Å—ã –≤—Ä–µ–º–µ–Ω–∏:**
    - ha/ta - –ø—Ä–æ—à–µ–¥—à–µ–µ
    - ake/te - –Ω–∞—Å—Ç–æ—è—â–µ–µ
    - ka/to - –±—É–¥—É—â–µ–µ
    """)

if __name__ == "__main__":
    main()