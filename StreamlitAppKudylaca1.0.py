import streamlit as st
import os
from typing import Dict, List, Tuple, Any
import tempfile

class MorphemicConlluSplitter:
    """–°–∏—Å—Ç–µ–º–∞ –º–æ—Ä—Ñ–µ–º–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –Ω–∞ —Ç—Ä–∏ CONLLU —Ñ–∞–π–ª–∞"""
    
    def __init__(self):
        self.affix_features = {
            # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã
            'ha': {'upos': 'PREF', 'feats': 'Tense=Past'},
            'ake': {'upos': 'PREF', 'feats': 'Tense=Present'},
            'ka': {'upos': 'PREF', 'feats': 'Tense=Future'},
            
            #–ú–æ–¥–∞–ª—å–Ω—ã–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã
            'to': {'upos': 'PREF', 'feats': 'Aspect=Perf|Polarity=Pos'},  # –ù–∞–ª–∏—á–∏–µ, –º–∞–∫—Å–∏–º–∞–ª–∏–∑–º, —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ—Å—Ç—å
            'te': {'upos': 'PREF', 'feats': 'Definite=Ind'},  # –ù–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç—å
            'ta': {'upos': 'PREF', 'feats': 'Polarity=Neg'},  # –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∏–ª–∏ –º–∞–ª–æ—Å—Ç—å
            
            # –°—É—Ñ—Ñ–∏–∫—Å—ã
            'ye': {'upos': 'SUFF', 'feats': 'VerbForm=Fin'},
            'yemu': {'upos': 'SUFF', 'feats': 'VerbForm=Conv'},
            'yepi': {'upos': 'SUFF', 'feats': 'VerbForm=Part'},
            'mu': {'upos': 'SUFF', 'feats': 'Derivation=Quality'},
            'pi': {'upos': 'SUFF', 'feats': 'Derivation=Relation'}
        }

        # –°–ø–∏—Å–∫–∏ –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
        self.time_prefixes = ['ha', 'ake', 'ka']
        self.semantic_prefixes = ['to', 'te', 'ta']
        self.all_prefixes = self.time_prefixes + self.semantic_prefixes

        # –°–ª–æ–≤–∞—Ä—å –∫–æ—Ä–Ω–µ–π-—Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã—Ö
        self.noun_roots = {
            'laca': '—á–µ–ª–æ–≤–µ–∫', 'tala': '—Å–º–µ—Ä—Ç—å', 'laa': '–≤–µ—Ç–µ—Ä', 
            'haka': '–æ–≥–æ–Ω—å', 'naro': '–≤–æ–¥–∞', 'ku': '—è', 'gy': '—Ç—ã',
            'ka': '—á—Ç–æ', 'la': '–≤–µ—Ç–µ—Ä', 'ranil': '—Å–æ–ª–Ω—Ü–µ', 'sari': '–ø–µ–Ω–∏–µ'
        }
    
    def analyze_word(self, word: str) -> Dict:
        """–ü—Ä–æ–≤–æ–¥–∏—Ç –º–æ—Ä—Ñ–µ–º–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–ª–æ–≤–∞"""
        morphemes = self._split_into_morphemes(word)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º UPOS –∫–æ—Ä–Ω—è
        root_upos = 'NOUN' if any(root in word for root in self.noun_roots) else 'VERB'
        
        return {
            'original_word': word,
            'morphemes': morphemes,
            'root_upos': root_upos
        }
    
    def _split_into_morphemes(self, word: str) -> List[Tuple[str, str]]:
        """–†–∞–∑–±–∏–≤–∞–µ—Ç —Å–ª–æ–≤–æ –Ω–∞ –º–æ—Ä—Ñ–µ–º—ã —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –∏—Ö —Ç–∏–ø–æ–≤"""
        morphemes = []
        remaining_word = word
        
        # –ò—â–µ–º –ø—Ä–µ—Ñ–∏–∫—Å—ã
        prefixes_found = True
        while prefixes_found and remaining_word:
            prefixes_found = False
            for prefix in self.all_prefixes:
                if remaining_word.startswith(prefix):
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø—Ä–µ—Ñ–∏–∫—Å–∞
                    if prefix in self.time_prefixes:
                        morphemes.append((prefix, 'time_prefix'))
                    else:  # semantic prefixes
                        morphemes.append((prefix, 'semantic_prefix'))
                    remaining_word = remaining_word[len(prefix):]
                    prefixes_found = True
                    break
        
        # –ò—â–µ–º –∫–æ—Ä–Ω–∏ (—Å–∞–º—ã–π –¥–ª–∏–Ω–Ω—ã–π —Å–æ–≤–ø–∞–¥–∞—é—â–∏–π –∫–æ—Ä–µ–Ω—å —Å–Ω–∞—á–∞–ª–∞)
        root_found = False
        for root in sorted(self.noun_roots.keys(), key=len, reverse=True):
            if remaining_word.startswith(root):
                morphemes.append((root, 'root'))
                remaining_word = remaining_word[len(root):]
                root_found = True
                break
        
        # –ï—Å–ª–∏ –∫–æ—Ä–µ–Ω—å –Ω–µ –Ω–∞–π–¥–µ–Ω —Å—Ä–µ–¥–∏ —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã—Ö, –±–µ—Ä–µ–º –ø–µ—Ä–≤—É—é —á–∞—Å—Ç—å –∫–∞–∫ –∫–æ—Ä–µ–Ω—å
        if not root_found and remaining_word:
            # –≠–≤—Ä–∏—Å—Ç–∏–∫–∞: –µ—Å–ª–∏ —Å–ª–æ–≤–æ –∫–æ—Ä–æ—Ç–∫–æ–µ, —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –º–µ—Å—Ç–æ–∏–º–µ–Ω–∏–µ
            if len(remaining_word) <= 2:
                morphemes.append((remaining_word, 'root'))
                remaining_word = ""
            else:
                # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∫–æ—Ä–µ–Ω—å –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º
                for i in range(min(4, len(remaining_word)), 0, -1):
                    potential_root = remaining_word[:i]
                    if any(noun_root.startswith(potential_root) for noun_root in self.noun_roots):
                        morphemes.append((potential_root, 'root'))
                        remaining_word = remaining_word[i:]
                        break
                else:
                    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é —á–∞—Å—Ç—å –∫–∞–∫ –∫–æ—Ä–µ–Ω—å
                    root_length = min(3, len(remaining_word))
                    morphemes.append((remaining_word[:root_length], 'root'))
                    remaining_word = remaining_word[root_length:]
        
        # –ò—â–µ–º —Å—É—Ñ—Ñ–∏–∫—Å—ã
        suffixes_found = True
        while suffixes_found and remaining_word:
            suffixes_found = False
            for suffix in ['yepi', 'yemu', 'ye', 'mu', 'pi']:
                if remaining_word.endswith(suffix):
                    morphemes.append((suffix, 'suffix'))
                    remaining_word = remaining_word[:-len(suffix)]
                    suffixes_found = True
                    break
        
        # –û—Å—Ç–∞—Ç–æ–∫ –ø–æ–º–µ—á–∞–µ–º –∫–∞–∫ unknown
        if remaining_word:
            morphemes.append((remaining_word, 'unknown'))
        
        return morphemes
    
    def generate_separate_conllu_files(self, words: List[str], base_output_path: str) -> Dict[str, str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç—Ä–∏ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö CONLLU —Ñ–∞–π–ª–∞"""
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–æ–≤
        affixes_content = [
            "# affixes.conllu - —Ç–æ–ª—å–∫–æ –∞—Ñ—Ñ–∏–∫—Å—ã", 
            "# language: kudylaca",
            "# sent_id | form | lemma | upos | xpos | feats | head | deprel | deps | misc",
            ""
        ]
        
        roots_content = [
            "# roots.conllu - —Ç–æ–ª—å–∫–æ –∫–æ—Ä–Ω–∏-—Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ", 
            "# language: kudylaca",
            "# sent_id | form | lemma | upos | xpos | feats | head | deprel | deps | misc",
            ""
        ]
        
        other_content = [
            "# other.conllu - –≤—Å—ë –æ—Å—Ç–∞–ª—å–Ω–æ–µ", 
            "# language: kudylaca",
            "# sent_id | form | lemma | upos | xpos | feats | head | deprel | deps | misc",
            ""
        ]
        
        sentence_id = 1
        
        for word in words:
            analysis = self.analyze_word(word)
            morphemes = analysis['morphemes']
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∑–∞–ø–∏—Å–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ –º–æ—Ä—Ñ–µ–º
            affix_records = []
            root_records = []
            other_records = []
            
            morpheme_position = 1
            
            for morpheme_form, morpheme_type in morphemes:
                conllu_line = self._create_conllu_line(
                    morpheme_form, morpheme_type, analysis, morpheme_position
                )
                
                # –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ —Ñ–∞–π–ª–∞–º
                if morpheme_type in ['time_prefix', 'semantic_prefix', 'suffix']:
                    affix_records.append(conllu_line)
                elif morpheme_type == 'root' and analysis['root_upos'] == 'NOUN':
                    root_records.append(conllu_line)
                else:
                    other_records.append(conllu_line)
                
                morpheme_position += 1

    def add_word_to_dictionary(self, word: str) -> Dict[str, str]:
        """–ë–∞–∑–æ–≤–∞—è –∑–∞–≥–ª—É—à–∫–∞ –¥–ª—è –º–µ—Ç–æ–¥–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å"""
        st.info(f"–§—É–Ω–∫—Ü–∏—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å–ª–æ–≤–∞ '{word}' –≤ —Å–ª–æ–≤–∞—Ä—å –±—É–¥–µ—Ç —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ –≤ —Å–ª–µ–¥—É—é—â–µ–π –≤–µ—Ä—Å–∏–∏")
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
        return {
            'affixes': "# –°–ª–æ–≤–∞—Ä—å –∞—Ñ—Ñ–∏–∫—Å–æ–≤\n# –í —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ",
            'roots': "# –°–ª–æ–≤–∞—Ä—å –∫–æ—Ä–Ω–µ–π\n# –í —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ", 
            'other': "# –°–ª–æ–≤–∞—Ä—å –ø—Ä–æ—á–µ–≥–æ\n# –í —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ"
        }
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã, –µ—Å–ª–∏ –µ—Å—Ç—å –∑–∞–ø–∏—Å–∏
            if affix_records:
                affixes_content.append(f"# sent_id = {sentence_id}")
                affixes_content.append(f"# text = {word}")
                affixes_content.extend(affix_records)
                affixes_content.append("")
            
            if root_records:
                roots_content.append(f"# sent_id = {sentence_id}")
                roots_content.append(f"# text = {word}")
                roots_content.extend(root_records)
                roots_content.append("")
            
            if other_records:
                other_content.append(f"# sent_id = {sentence_id}")
                other_content.append(f"# text = {word}")
                other_content.extend(other_records)
                other_content.append("")
            
            sentence_id += 1
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª—ã
        results = {}
        
        affixes_path = f"{base_output_path}_affixes.conllu"
        with open(affixes_path, 'w', encoding='utf-8', newline='\n') as f:
            f.write("\n".join(affixes_content))
        results['affixes'] = affixes_path
        
        roots_path = f"{base_output_path}_roots.conllu"
        with open(roots_path, 'w', encoding='utf-8', newline='\n') as f:
            f.write("\n".join(roots_content))
        results['roots'] = roots_path
        
        other_path = f"{base_output_path}_other.conllu"
        with open(other_path, 'w', encoding='utf-8', newline='\n') as f:
            f.write("\n".join(other_content))
        results['other'] = other_path
        
        return results

    def add_word_to_dictionary(self, word: str) -> Dict[str, str]:
        """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–ª–æ–≤–∞ –≤ —Å–ª–æ–≤–∞—Ä—å —Å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        # ... –≤–µ—Å—å –∫–æ–¥ –º–µ—Ç–æ–¥–∞ add_word_to_dictionary ...
    
    def _get_word_meanings(self, word: str, analysis: Dict) -> Dict[str, str]:
        """–ó–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏—è –º–æ—Ä—Ñ–µ–º —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        # ... –≤–µ—Å—å –∫–æ–¥ –º–µ—Ç–æ–¥–∞ _get_word_meanings ...
    
    def _create_dictionary_entries(self, word: str, analysis: Dict, meanings: Dict[str, str]) -> Dict[str, str]:
        """–°–æ–∑–¥–∞—ë—Ç —Å–ª–æ–≤–∞—Ä–Ω—ã–µ —Å—Ç–∞—Ç—å–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ CONLLU"""
        # ... –≤–µ—Å—å –∫–æ–¥ –º–µ—Ç–æ–¥–∞ _create_dictionary_entries ...
    
    def _create_dictionary_entry(self, form: str, morpheme_type: str, analysis: Dict, 
                               meanings: Dict[str, str], position: int) -> str:
        """–°–æ–∑–¥–∞–µ—Ç —Å–ª–æ–≤–∞—Ä–Ω—É—é —Å—Ç–∞—Ç—å—é –¥–ª—è –º–æ—Ä—Ñ–µ–º—ã"""
        # ... –≤–µ—Å—å –∫–æ–¥ –º–µ—Ç–æ–¥–∞ _create_dictionary_entry ...
    
    def generate_conllu_content(self, words: List[str]) -> Dict[str, str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ CONLLU —Ñ–∞–π–ª–æ–≤ –±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–∞ –¥–∏—Å–∫"""
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–æ–≤
        affixes_content = [
            "# affixes.conllu - —Ç–æ–ª—å–∫–æ –∞—Ñ—Ñ–∏–∫—Å—ã", 
            "# language: kudylaca",
            "# sent_id | form | lemma | upos | xpos | feats | head | deprel | deps | misc",
            ""
        ]
        
        roots_content = [
            "# roots.conllu - —Ç–æ–ª—å–∫–æ –∫–æ—Ä–Ω–∏-—Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ", 
            "# language: kudylaca",
            "# sent_id | form | lemma | upos | xpos | feats | head | deprel | deps | misc",
            ""
           
        ]
        
        other_content = [
            "# other.conllu - –≤—Å—ë –æ—Å—Ç–∞–ª—å–Ω–æ–µ", 
            "# language: kudylaca",
            "# sent_id | form | lemma | upos | xpos | feats | head | deprel | deps | misc",
            ""
        ]
        
        sentence_id = 1
        
        for word in words:
            analysis = self.analyze_word(word)
            morphemes = analysis['morphemes']
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∑–∞–ø–∏—Å–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ –º–æ—Ä—Ñ–µ–º
            affix_records = []
            root_records = []
            other_records = []
            
            morpheme_position = 1
            
            for morpheme_form, morpheme_type in morphemes:
                conllu_line = self._create_conllu_line(
                    morpheme_form, morpheme_type, analysis, morpheme_position
                )
                
                # –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ —Ñ–∞–π–ª–∞–º
                if morpheme_type in ['time_prefix', 'semantic_prefix', 'suffix']:
                    affix_records.append(conllu_line)
                elif morpheme_type == 'root' and analysis['root_upos'] == 'NOUN':
                    root_records.append(conllu_line)
                else:
                    other_records.append(conllu_line)
                
                morpheme_position += 1
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã, –µ—Å–ª–∏ –µ—Å—Ç—å –∑–∞–ø–∏—Å–∏
            if affix_records:
                affixes_content.append(f"# sent_id = {sentence_id}")
                affixes_content.append(f"# text = {word}")
                affixes_content.extend(affix_records)
                affixes_content.append("")
            
            if root_records:
                roots_content.append(f"# sent_id = {sentence_id}")
                roots_content.append(f"# text = {word}")
                roots_content.extend(root_records)
                roots_content.append("")
            
            if other_records:
                other_content.append(f"# sent_id = {sentence_id}")
                other_content.append(f"# text = {word}")
                other_content.extend(other_records)
                other_content.append("")
            
            sentence_id += 1
        
        return {
            'affixes': "\n".join(affixes_content),
            'roots': "\n".join(roots_content),
            'other': "\n".join(other_content)
        }
    
    def _create_conllu_line(self, form: str, morpheme_type: str, analysis: Dict, position: int) -> str:
        """–°–æ–∑–¥–∞–µ—Ç —Å—Ç—Ä–æ–∫—É CONLLU –¥–ª—è –º–æ—Ä—Ñ–µ–º—ã"""
        
        # –ë–∞–∑–æ–≤—ã–µ –ø–æ–ª—è
        fields = {
            'id': str(position),
            'form': form,
            'lemma': form,
            'upos': 'X',
            'xpos': '_',
            'feats': '_',
            'head': '0',
            'deprel': 'root',
            'deps': '_',
            'misc': '_'
        }
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –º–æ—Ä—Ñ–µ–º—ã
        if morpheme_type in ['time_prefix', 'semantic_prefix', 'suffix']:
            affix_info = self.affix_features.get(form, {})
            fields['upos'] = affix_info.get('upos', 'PREF' if morpheme_type == 'time_prefix' else 'SUFF')
            fields['feats'] = affix_info.get('feats', '_')
            fields['misc'] = f"Type={morpheme_type}"
            
        elif morpheme_type == 'root':
            if analysis['root_upos'] == 'NOUN':
                fields['upos'] = 'NOUN'
                meaning = self.noun_roots.get(form, 'unknown')
                fields['feats'] = f"Meaning={meaning}"
                fields['misc'] = "Type=root_noun"
            else:
                fields['upos'] = analysis['root_upos']
                fields['misc'] = f"Type=root_{analysis['root_upos'].lower()}"
                
        else:  # unknown
            fields['misc'] = f"NotMorpheme|Type={morpheme_type}"
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫—É CONLLU
        return f"{fields['id']}\t{fields['form']}\t{fields['lemma']}\t{fields['upos']}\t{fields['xpos']}\t{fields['feats']}\t{fields['head']}\t{fields['deprel']}\t{fields['deps']}\t{fields['misc']}"

    def demonstrate_analysis(self, words: List[str], dictionary_mode: bool = False):
        """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ —Å–ª–æ–≤ –≤ —Å–ª–æ–≤–∞—Ä–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ"""
        st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–æ—Ä—Ñ–µ–º–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞" + (" (—Å–ª–æ–≤–∞—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç)" if dictionary_mode else ""))
        
        for word in words:
            st.write(f"**–°–ª–æ–≤–æ:** `{word}`")
            analysis = self.analyze_word(word)
            morphemes = analysis['morphemes']
            
            if dictionary_mode:
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–∞–∑–±–æ—Ä –≤ —Å–ª–æ–≤–∞—Ä–Ω–æ–º —Å—Ç–∏–ª–µ
                with st.expander(f"–°–ª–æ–≤–∞—Ä–Ω–∞—è —Å—Ç–∞—Ç—å—è –¥–ª—è: {word}"):
                    for i, (form, mtype) in enumerate(morphemes, 1):
                        if mtype == 'root':
                            meaning = self.noun_roots.get(form, '–∑–Ω–∞—á–µ–Ω–∏–µ –Ω–µ —É–∫–∞–∑–∞–Ω–æ')
                            st.write(f"{i}. **{form}** ({mtype}) - {meaning}")
                        else:
                            affix_info = self.affix_features.get(form, {})
                            feats = affix_info.get('feats', '–∞—Ñ—Ñ–∏–∫—Å')
                            st.write(f"{i}. {form} ({mtype}) - {feats}")
            else:
                # –°—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                morphemes_text = " + ".join([f"{form} ({mtype})" for form, mtype in morphemes])
                st.write(f"**–ú–æ—Ä—Ñ–µ–º–Ω—ã–π —Ä–∞–∑–±–æ—Ä:** {morphemes_text}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ñ–∞–π–ª–∞–º (–æ—Å—Ç–∞–≤–∏—Ç—å –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
            affixes = [f for f, t in morphemes if t in ['time_prefix', 'semantic_prefix', 'suffix']]
            roots = [f for f, t in morphemes if t == 'root' and analysis['root_upos'] == 'NOUN']
            other = [f for f, t in morphemes if not (t in ['time_prefix', 'semantic_prefix', 'suffix'] or 
                                                     (t == 'root' and analysis['root_upos'] == 'NOUN'))]
            
            st.write("**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ñ–∞–π–ª–∞–º CONLLU:**")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                if affixes:
                    st.info(f"üìÅ **affixes.conllu:** {', '.join(affixes)}")
                else:
                    st.info("üìÅ **affixes.conllu:** -")
            
            with col2:
                if roots:
                    st.success(f"üìÅ **roots.conllu:** {', '.join(roots)}")
                else:
                    st.success("üìÅ **roots.conllu:** -")
            
            with col3:
                if other:
                    st.warning(f"üìÅ **other.conllu:** {', '.join(other)}")
                else:
                    st.warning("üìÅ **other.conllu:** -")
            
            st.divider()

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è Streamlit –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    st.set_page_config(
        page_title="Morphemic Analyzer",
        page_icon="üìö",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
    st.title("üìö –°–∏—Å—Ç–µ–º–∞ –º–æ—Ä—Ñ–µ–º–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ KUDYLACA")
    st.markdown("### —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –Ω–∞ 3 CONLLU —Ñ–∞–π–ª–∞")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
    if 'splitter' not in st.session_state:
        st.session_state.splitter = MorphemicConlluSplitter()
    
    splitter = st.session_state.splitter
    
    # –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å —Å –Ω–∞–≤–∏–≥–∞—Ü–∏–µ–π
    st.sidebar.title("–ù–∞–≤–∏–≥–∞—Ü–∏—è")
    option = st.sidebar.radio(
        "–í—ã–±–µ—Ä–∏—Ç–µ –æ–ø—Ü–∏—é:",
        ["üè† –ì–ª–∞–≤–Ω–∞—è", "üîç –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞", "üìù –ê–Ω–∞–ª–∏–∑ —Å–≤–æ–∏—Ö —Å–ª–æ–≤", 
         "üìñ –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ —Å–ª–æ–≤–∞—Ä—å", "üíæ –°–æ–∑–¥–∞–Ω–∏–µ CONLLU —Ñ–∞–π–ª–æ–≤"]
    )
    # –ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞
    if option == "üè† –ì–ª–∞–≤–Ω–∞—è":
        st.header("–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ —Å–∏—Å—Ç–µ–º—É –º–æ—Ä—Ñ–µ–º–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞!")
        
        st.markdown("""
        –≠—Ç–∞ —Å–∏—Å—Ç–µ–º–∞ –≤—ã–ø–æ–ª–Ω—è–µ—Ç –º–æ—Ä—Ñ–µ–º–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–ª–æ–≤ —è–∑—ã–∫–∞ KUDYLACA –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç—Ä–∏ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö CONLLU —Ñ–∞–π–ª–∞:
        
        - üìÅ **affixes.conllu** - –ø—Ä–µ—Ñ–∏–∫—Å—ã –∏ —Å—É—Ñ—Ñ–∏–∫—Å—ã
        - üìÅ **roots.conllu** - –∫–æ—Ä–Ω–∏-—Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ  
        - üìÅ **other.conllu** - –≤—Å—ë –æ—Å—Ç–∞–ª—å–Ω–æ–µ
        
        ### –ü—Ä–∏–º–µ—Ä—ã —Å–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:
        - `halacayemu` - —á–µ–ª–æ–≤–µ—á–µ–Ω (–ø—Ä–æ—à–µ–¥—à–µ–µ –≤—Ä–µ–º—è, –¥–µ–µ–ø—Ä–∏—á–∞—Å—Ç–∏–µ)
        - `hatalaye` - –Ω–µ –∏–¥—Ç–∏ (–ø—Ä–æ—à–µ–¥—à–µ–µ –≤—Ä–µ–º—è)
        - `aketolaye` - –≤—ã–∂–∏–ª (–Ω–∞—Å—Ç–æ—è—â–µ–µ/ —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ–µ)
        """)
        
        # –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç
        if st.button("üöÄ –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –Ω–∞ –ø—Ä–∏–º–µ—Ä–∞—Ö"):
            test_words = ["halacayemu", "takulaye", "aketolaye", "gy", "tolacaye"]
            splitter.demonstrate_analysis(test_words, dictionary_mode=True)
    
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞
    elif option == "üîç –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞":
        st.header("–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –º–æ—Ä—Ñ–µ–º–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
        
        st.info("""
        –ù–∞ —ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ –≤—ã –º–æ–∂–µ—Ç–µ —É–≤–∏–¥–µ—Ç—å –∞–Ω–∞–ª–∏–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤—ã—Ö —Å–ª–æ–≤.
        –°–∏—Å—Ç–µ–º–∞ –ø–æ–∫–∞–∂–µ—Ç –º–æ—Ä—Ñ–µ–º–Ω—ã–π —Ä–∞–∑–±–æ—Ä –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞ –∏ –µ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ CONLLU —Ñ–∞–π–ª–∞–º.
        """)
        
        test_words = ["halacayemu", "takulaye", "aketolaye", "gy", "tolacaye"]
        
        if st.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—é"):
            splitter.demonstrate_analysis(test_words, dictionary_mode=True)
    
    # –ê–Ω–∞–ª–∏–∑ —Å–≤–æ–∏—Ö —Å–ª–æ–≤
    elif option == "üìù –ê–Ω–∞–ª–∏–∑ —Å–≤–æ–∏—Ö —Å–ª–æ–≤":
        st.header("–ê–Ω–∞–ª–∏–∑ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö —Å–ª–æ–≤")
        
        st.info("""
        –í–≤–µ–¥–∏—Ç–µ —Å–ª–æ–≤–∞ –¥–ª—è –º–æ—Ä—Ñ–µ–º–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞. –ö–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–π —Å—Ç—Ä–æ–∫–µ.
        –ü—Ä–∏–º–µ—Ä—ã: `halacayemu`, `takulaye`, `aketolaye`
        """)
        
        # –ü–æ–ª–µ –¥–ª—è –≤–≤–æ–¥–∞ —Å–ª–æ–≤
        words_input = st.text_area(
            "–í–≤–µ–¥–∏—Ç–µ —Å–ª–æ–≤–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:",
            height=150,
            placeholder="halacayemu\ntakulaye\nsarimu\naketolaye"
        )
        
        if st.button("–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–ª–æ–≤–∞"):
            if words_input.strip():
                words = [word.strip() for word in words_input.split('\n') if word.strip()]
                splitter.demonstrate_analysis(words)
            else:
                st.error("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ —Å–ª–æ–≤–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")
        # –ù–æ–≤–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å
    elif option == "üìñ –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ —Å–ª–æ–≤–∞—Ä—å":
        st.header("üìñ –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–ª–æ–≤ –≤ —Å–ª–æ–≤–∞—Ä—å KUDYLACA")
        
        st.info("""
        –ù–∞ —ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ –≤—ã –º–æ–∂–µ—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ —Å–ª–æ–≤–∞—Ä—å —è–∑—ã–∫–∞ KUDYLACA.
        –ü—Ä–æ—Ü–µ—Å—Å –¥–æ–±–∞–≤–ª–µ–Ω–∏—è:
        1. –í–≤–µ–¥–∏—Ç–µ —Å–ª–æ–≤–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞–∑–±–æ—Ä –Ω–∞ –º–æ—Ä—Ñ–µ–º—ã
        3. –ü–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å —Ä–∞–∑–±–æ—Ä–∞
        4. –£–∫–∞–∂–∏—Ç–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –Ω–æ–≤—ã—Ö –∫–æ—Ä–Ω–µ–π
        5. –°–ª–æ–≤–∞—Ä–Ω—ã–µ —Å—Ç–∞—Ç—å–∏ –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ CONLLU —Ñ–∞–π–ª—ã
        """)
        
        word = st.text_input("–í–≤–µ–¥–∏—Ç–µ —Å–ª–æ–≤–æ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å:", key="dict_word")
        
        if word:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
    def add_word_to_dictionary(self, word: str) -> Dict[str, str]:
        """–ü—Ä–æ—Å—Ç–∞—è –≤–µ—Ä—Å–∏—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å–ª–æ–≤–∞ –≤ —Å–ª–æ–≤–∞—Ä—å"""
        
        analysis = self.analyze_word(word)
        morphemes = analysis['morphemes']
        
        st.write(f"**–ê–Ω–∞–ª–∏–∑ —Å–ª–æ–≤–∞:** {word}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–∞–∑–±–æ—Ä
        for form, mtype in morphemes:
            st.write(f"- {form} ({mtype})")
        
        # –ü—Ä–æ—Å–∏–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
        if st.button("‚úÖ –ü–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å —Ä–∞–∑–±–æ—Ä –∏ –¥–æ–±–∞–≤–∏—Ç—å –≤ —Å–ª–æ–≤–∞—Ä—å"):
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—ã–µ —Å–ª–æ–≤–∞—Ä–Ω—ã–µ —Å—Ç–∞—Ç—å–∏
            return self._create_simple_dictionary_entries(word, analysis)
        
        return {}

    def _create_simple_dictionary_entries(self, word: str, analysis: Dict) -> Dict[str, str]:
        """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ—Å—Ç—ã–µ —Å–ª–æ–≤–∞—Ä–Ω—ã–µ —Å—Ç–∞—Ç—å–∏"""
        
        entries = {
            'affixes': ["# –°–ª–æ–≤–∞—Ä—å –∞—Ñ—Ñ–∏–∫—Å–æ–≤ KUDYLACA", ""],
            'roots': ["# –°–ª–æ–≤–∞—Ä—å –∫–æ—Ä–Ω–µ–π KUDYLACA", ""],
            'other': ["# –°–ª–æ–≤–∞—Ä—å –ø—Ä–æ—á–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ KUDYLACA", ""]
        }
        
        for i, (form, mtype) in enumerate(analysis['morphemes'], 1):
            entry = f"{i}\t{form}\t{form}\tX\t_\t_\t0\troot\t_\tType={mtype}"
            
            if mtype in ['time_prefix', 'semantic_prefix', 'suffix']:
                entries['affixes'].append(entry)
            elif mtype == 'root':
                entries['roots'].append(entry)
            else:
                entries['other'].append(entry)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—Ä
        for key in entries:
            entries[key].extend(["", f"# –ü—Ä–∏–º–µ—Ä: {word}", ""])
        
        return {k: "\n".join(v) for k, v in entries.items()}
            
            if dictionary_entries:
                st.success("‚úÖ –°–ª–æ–≤–æ —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ —Å–ª–æ–≤–∞—Ä—å!")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ–∑–¥–∞–Ω–Ω—ã–µ —Å–ª–æ–≤–∞—Ä–Ω—ã–µ —Å—Ç–∞—Ç—å–∏
                st.subheader("–°–æ–∑–¥–∞–Ω–Ω—ã–µ —Å–ª–æ–≤–∞—Ä–Ω—ã–µ —Å—Ç–∞—Ç—å–∏:")
                
                tab1, tab2, tab3 = st.tabs(["üìÅ –ê—Ñ—Ñ–∏–∫—Å—ã", "üìÅ –ö–æ—Ä–Ω–∏", "üìÅ –ü—Ä–æ—á–µ–µ"])
                
                with tab1:
                    st.code(dictionary_entries['affixes'], language="text")
                    st.download_button(
                        label="üì• –°–∫–∞—á–∞—Ç—å —Å–ª–æ–≤–∞—Ä—å –∞—Ñ—Ñ–∏–∫—Å–æ–≤",
                        data=dictionary_entries['affixes'],
                        file_name="kudylaca_affixes_dictionary.conllu",
                        mime="text/plain"
                    )
                
                with tab2:
                    st.code(dictionary_entries['roots'], language="text")
                    st.download_button(
                        label="üì• –°–∫–∞—á–∞—Ç—å —Å–ª–æ–≤–∞—Ä—å –∫–æ—Ä–Ω–µ–π", 
                        data=dictionary_entries['roots'],
                        file_name="kudylaca_roots_dictionary.conllu",
                        mime="text/plain"
                    )
                
                with tab3:
                    st.code(dictionary_entries['other'], language="text")
                    st.download_button(
                        label="üì• –°–∫–∞—á–∞—Ç—å —Å–ª–æ–≤–∞—Ä—å –ø—Ä–æ—á–µ–≥–æ",
                        data=dictionary_entries['other'],
                        file_name="kudylaca_other_dictionary.conllu", 
                        mime="text/plain"
                    )
    # –°–æ–∑–¥–∞–Ω–∏–µ CONLLU —Ñ–∞–π–ª–æ–≤
    elif option == "üíæ –°–æ–∑–¥–∞–Ω–∏–µ CONLLU —Ñ–∞–π–ª–æ–≤":
        st.header("–°–æ–∑–¥–∞–Ω–∏–µ CONLLU —Ñ–∞–π–ª–æ–≤")
        
        st.info("""
        –ù–∞ —ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ –≤—ã –º–æ–∂–µ—Ç–µ –≤–≤–µ—Å—Ç–∏ —Å–ª–æ–≤–∞ –∏ –ø–æ–ª—É—á–∏—Ç—å —Ç—Ä–∏ CONLLU —Ñ–∞–π–ª–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞.
        –§–∞–π–ª—ã –º–æ–∂–Ω–æ –±—É–¥–µ—Ç –ø—Ä–æ—Å–º–æ—Ç—Ä–µ—Ç—å –æ–Ω–ª–∞–π–Ω –∏–ª–∏ —Å–∫–∞—á–∞—Ç—å.
        """)
        
        # –ü–æ–ª–µ –¥–ª—è –≤–≤–æ–¥–∞ —Å–ª–æ–≤
        words_input = st.text_area(
            "–í–≤–µ–¥–∏—Ç–µ —Å–ª–æ–≤–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è CONLLU —Ñ–∞–π–ª–æ–≤:",
            height=150,
            placeholder="halacayemu\ntakulaye\nsarimu\naketolaye",
            key="conllu_words"
        )
        
        base_filename = st.text_input("–ë–∞–∑–æ–≤–æ–µ –∏–º—è –¥–ª—è —Ñ–∞–π–ª–æ–≤ (–±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è):", value="morphemic_analysis")
        
        if st.button("–°–æ–∑–¥–∞—Ç—å CONLLU —Ñ–∞–π–ª—ã"):
            if words_input.strip():
                words = [word.strip() for word in words_input.split('\n') if word.strip()]
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–æ–≤
                conllu_content = splitter.generate_conllu_content(words)
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–æ–≤
                st.success("‚úÖ CONLLU —Ñ–∞–π–ª—ã —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω—ã!")
                
                # –í–∫–ª–∞–¥–∫–∏ –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
                tab1, tab2, tab3 = st.tabs(["üìÅ Affixes", "üìÅ Roots", "üìÅ Other"])
                
                with tab1:
                    st.subheader("affixes.conllu")
                    st.code(conllu_content['affixes'], language="text")
                    
                    # –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
                    st.download_button(
                        label="üì• –°–∫–∞—á–∞—Ç—å affixes.conllu",
                        data=conllu_content['affixes'],
                        file_name=f"{base_filename}_affixes.conllu",
                        mime="text/plain"
                    )
                
                with tab2:
                    st.subheader("roots.conllu")
                    st.code(conllu_content['roots'], language="text")
                    
                    # –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
                    st.download_button(
                        label="üì• –°–∫–∞—á–∞—Ç—å roots.conllu",
                        data=conllu_content['roots'],
                        file_name=f"{base_filename}_roots.conllu",
                        mime="text/plain"
                    )
                
                with tab3:
                    st.subheader("other.conllu")
                    st.code(conllu_content['other'], language="text")
                    
                    # –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
                    st.download_button(
                        label="üì• –°–∫–∞—á–∞—Ç—å other.conllu",
                        data=conllu_content['other'],
                        file_name=f"{base_filename}_other.conllu",
                        mime="text/plain"
                    )
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∞–Ω–∞–ª–∏–∑ —Å–ª–æ–≤
                st.subheader("üìä –ê–Ω–∞–ª–∏–∑ —Å–ª–æ–≤")
                splitter.demonstrate_analysis(words)
                
            else:
                st.error("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ —Å–ª–æ–≤–æ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤.")
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —è–∑—ã–∫–µ –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏
    st.sidebar.markdown("---")
    st.sidebar.subheader("–û —è–∑—ã–∫–µ KUDYLACA")
    st.sidebar.markdown("""
    **–ö–æ—Ä–Ω–∏-—Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ:**
    - laca - —á–µ–ª–æ–≤–µ–∫
    - tala - —Å–º–µ—Ä—Ç—å  
    - laa - –ª—é–±–æ–≤—å
    - haka - –≤—Ä–µ–º—è
    - naro - –ø—Ä–∏–≤–µ—Ç
    
    **–ê—Ñ—Ñ–∏–∫—Å—ã –≤—Ä–µ–º–µ–Ω–∏:**
    - ha - –ø—Ä–æ—à–µ–¥—à–µ–µ
    - ake - –Ω–∞—Å—Ç–æ—è—â–µ–µ
    - ka - –±—É–¥—É—â–µ–µ

     **–ê—Ñ—Ñ–∏–∫—Å—ã —Å–æ—Å—Ç–æ—è–Ω–∏—è:**
    - ta - –û—Ç—Å—É—Ç—Å–≤–∏–µ, –º–∞–ª–æ—Å—Ç—å
    - te - –ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç—å
    - to - –ù–∞–ª–∏—á–∏–µ, –º–∞–∫—Å–∏–º–∞–ª–∏–∑–º, –ø—Ä–∏ –≥–ª–∞–≥–æ–ª–µ —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–∞—è —Ñ–æ—Ä–º–∞
    """)

if __name__ == "__main__":
    main()
